![grab-landing-page](/pgarde1.png)

## Objectifs : 
*Maitriser l’API de twitter pour l’extraction des tweets 
*Maitriser la partie NLP (natural language processing) avec NLTK en Python 
*Appliquer les principes de nettoyage des données 
*Classer les tweets : regrouper ensemble les tweets qui sont similaires. C’est une étape qui peut être considérée comme une étape:
lien binder pour le travail de cleaning and clustering (TweetsClusteringProject_HajerMhimdi.ipynb)

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/HajerMhimdi/TweetsClusteringProject_MhimdiHajer.git/main?filepath=TweetsClusteringProject_HajerMhimdi.ipynb)


lien binder pour l'extraction des API Tweets (TweetsClusteringProject_HajerMhimdi.ipynb)
[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/HajerMhimdi/TweetsClusteringProject_MhimdiHajer.git/main?filepath=TweetExtraction.ipynb)


# <font color='green'> <center> vue globale etape d'extraction et cleaning data

![grab-landing-page](Extracting_and_cleaningData.gif)

# <font color='green'> <center>etape de clustering



### <font color='blue'> <center> Word2Vec method and cosinus Similarity

![grab-landing-page](/methode1_word2Vec.gif)

### <font color='blue'> <center> Mini batch Kmeans nombre Cluster =25 (exemple)

![grab-landing-page](MiniBatchKmeans30.gif)


