![grab-landing-page](/pgarde1.png)

## Objectifs : 
#### <br>*Maitriser l’API de twitter pour l’extraction des tweets 
#### <br>*Maitriser la partie NLP (natural language processing) avec NLTK en Python 
#### <br>*Appliquer les principes de nettoyage des données 
#### <br>*Classer les tweets : regrouper ensemble les tweets qui sont similaires. C’est une étape qui peut être considérée comme une étape:
<br>lien binder pour le travail de cleaning and clustering (TweetsClusteringProject_HajerMhimdi.ipynb)

<br>[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/HajerMhimdi/TweetsClusteringProject_MhimdiHajer.git/main?filepath=TweetsClusteringProject_HajerMhimdi.ipynb)


<br>lien binder pour l'extraction des API Tweets (TweetsClusteringProject_HajerMhimdi.ipynb)
<br>[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/HajerMhimdi/TweetsClusteringProject_MhimdiHajer.git/main?filepath=TweetExtraction.ipynb)


# <font color='green'> <center> vue globale etape d'extraction et cleaning data

![grab-landing-page](Extracting_and_cleaningData.gif)

# <font color='green'> <center>etape de clustering



### <font color='blue'> <center> Word2Vec method and cosinus Similarity

![grab-landing-page](/methode1_word2Vec.gif)

### <font color='blue'> <center> Mini batch Kmeans nombre Cluster =25 (exemple)

![grab-landing-page](MiniBatchKmeans30.gif)


### Références:
https://www.youtube.com/results?search_query=sklearn+python
http://www.nltk.org/api/nltk.cluster.html
http://www.pitt.edu/~naraehan/presentation/word2vec-try.html
https://rdrr.io/cran/ClusterR/man/MiniBatchKmeans.html
https://www.programcreek.com/python/example/103492/sklearn.cluster.MiniBatchKMeans
https://www.geeksforgeeks.org/difference-between-pca-vs-t-sne/?fbclid=IwAR3FNrnHrVbVslbuEwjPW9tsCW2GsVpPVTw4qWmBe7ypNwL1c_Yi1b_CdKo
